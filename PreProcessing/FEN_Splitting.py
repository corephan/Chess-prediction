import os
import random
import mmap
import gc
from tqdm import tqdm
import time

# =================================================================
# üéõÔ∏è C·∫§U H√åNH H·ªÜ TH·ªêNG
# =================================================================
# L·∫•y ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c g·ªëc c·ªßa project (l√πi l√™n 1 c·∫•p t·ª´ PreProcessing)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# ƒê∆∞·ªùng d·∫´n file ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói c√∫ ph√°p:
# S·ª≠ d·ª•ng os.path.join ƒë·ªÉ k·∫øt h·ª£p c√°c th√†nh ph·∫ßn ƒë∆∞·ªùng d·∫´n.
FILE_MAIN = os.path.join(BASE_DIR, 'DataSets', 'pgnData', '(1).pgn')
FILE_DRAW = os.path.join(BASE_DIR, 'DataSets', 'pgnData', 'all_draws_combined.pgn')
OUTPUT_DIR = os.path.join(BASE_DIR, 'DataSets', 'pgnData (Balanced)')

# Ch·ªâ ti√™u (S·ªë l∆∞·ª£ng v√°n m·ªói l·ªõp)
TARGET_PER_CLASS = 100000
RATIOS = (0.8, 0.1, 0.1)

def scan_pgn_indices_fast(file_path):
    """Qu√©t file si√™u t·ªëc d√πng mmap"""
    if not os.path.exists(file_path):
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y {file_path}")
        # Tr·∫£ v·ªÅ k·∫øt qu·∫£ r·ªóng ƒë·ªÉ tr√°nh l·ªói ti·∫øp theo
        return {'1-0': [], '0-1': [], '1/2-1/2': []} 

    indices = {'1-0': [], '0-1': [], '1/2-1/2': []}
    file_size = os.path.getsize(file_path)
    
    print(f"üîç ƒêang ƒë√°nh ch·ªâ m·ª•c: {os.path.basename(file_path)} ({file_size/1024/1024:.1f} MB)...")
    
    try:
        with open(file_path, "rb") as f:
            # D√πng mmap ƒë·ªÉ truy c·∫≠p file nh∆∞ RAM
            # Th√™m try-except block cho mmap n·∫øu file qu√° l·ªõn ho·∫∑c c√≥ v·∫•n ƒë·ªÅ v·ªÅ quy·ªÅn truy c·∫≠p
            with mmap.mmap(f.fileno(), length=0, access=mmap.ACCESS_READ) as mm:
                cursor = 0
                # Pre-compile c√°c chu·ªói bytes ƒë·ªÉ so s√°nh nhanh h∆°n
                KEY_EVENT = b"[Event"
                RES_W = b'[Result "1-0"]'
                RES_L = b'[Result "0-1"]'
                RES_D = b'[Result "1/2-1/2"]'
                
                # B·∫Øt ƒë·∫ßu thanh progress
                with tqdm(total=file_size, unit='B', unit_scale=True, desc="Indexing") as pbar:
                    
                    # T√¨m v√°n ƒë·∫ßu ti√™n
                    start_pos = mm.find(KEY_EVENT, cursor)
                    while start_pos != -1:
                        # T√¨m v√°n ti·∫øp theo
                        next_pos = mm.find(KEY_EVENT, start_pos + 1)
                        
                        # T√≠nh ƒë·ªô d√†i v√°n c·ªù
                        if next_pos == -1:
                            length = file_size - start_pos
                        else:
                            length = next_pos - start_pos
                        
                        # ƒê·ªçc Header (t·ªëi ƒëa 2048 bytes ƒë·∫ßu) ƒë·ªÉ t√¨m k·∫øt qu·∫£
                        # M·ªôt s·ªë PGN c√≥ header d√†i; tƒÉng ng∆∞·ª°ng ƒë·ªÉ b·ªÅn h∆°n
                        head = mm[start_pos : start_pos + min(length, 2048)]
                        
                        # Check nhanh
                        if RES_W in head:
                            indices['1-0'].append((start_pos, length))
                        elif RES_L in head:
                            indices['0-1'].append((start_pos, length))
                        elif RES_D in head:
                            indices['1/2-1/2'].append((start_pos, length))
                        
                        # C·∫≠p nh·∫≠t thanh progress
                        processed = (next_pos if next_pos != -1 else file_size) - cursor
                        pbar.update(processed)
                        
                        # C·∫≠p nh·∫≠t con tr·ªè cho l·∫ßn l·∫∑p ti·∫øp theo
                        cursor = next_pos if next_pos != -1 else file_size
                        start_pos = next_pos
    except Exception as e:
        print(f"‚ùå L·ªói trong qu√° tr√¨nh ƒë√°nh ch·ªâ m·ª•c: {e}")
        return {'1-0': [], '0-1': [], '1/2-1/2': []}
        
    return indices

def process_and_merge():
    # Th√™m ki·ªÉm tra file ƒë·∫ßu v√†o tr∆∞·ªõc khi ch·∫°y
    if not (os.path.exists(FILE_MAIN) and os.path.exists(FILE_DRAW)):
        print("üö® L·ªói: Kh√¥ng t√¨m th·∫•y √≠t nh·∫•t m·ªôt trong hai file ngu·ªìn. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.")
        print(f"  MAIN: {FILE_MAIN}")
        print(f"  DRAW: {FILE_DRAW}")
        return

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # 1. SCAN D·ªÆ LI·ªÜU
    idxs_main = scan_pgn_indices_fast(FILE_MAIN)
    pool_w = idxs_main['1-0']
    pool_l = idxs_main['0-1']
    # Gi·∫£i ph√≥ng memory ngay l·∫≠p t·ª©c cho ph·∫ßn kh√¥ng d√πng
    del idxs_main
    gc.collect() 
    
    idxs_draw = scan_pgn_indices_fast(FILE_DRAW)
    pool_d = idxs_draw['1/2-1/2']
    del idxs_draw
    gc.collect()

    print(f"\nüìä KHO D·ªÆ LI·ªÜU:")
    print(f" ¬† - White Wins: {len(pool_w)}")
    print(f" ¬† - Black Wins: {len(pool_l)}")
    print(f" ¬† - Draws: ¬† ¬† ¬†{len(pool_d)}")

    # 2. SAMPLING (L·∫§Y M·∫™U)
    # H√†m l·∫•y m·∫´u ng·∫´u nhi√™n an to√†n
    def safe_sample(pool, n, label):
        if len(pool) < n:
            print(f"‚ö†Ô∏è C·∫£nh b√°o: {label} ch·ªâ c√≥ {len(pool)} (C·∫ßn {n}). L·∫•y t·∫•t c·∫£.")
            # T·∫°o b·∫£n sao tr∆∞·ªõc khi x√°o tr·ªôn ƒë·ªÉ kh√¥ng l√†m thay ƒë·ªïi pool g·ªëc
            sampled = pool[:] 
            random.shuffle(sampled)
            return sampled
        return random.sample(pool, n)

    final_w = safe_sample(pool_w, TARGET_PER_CLASS, "White")
    final_l = safe_sample(pool_l, TARGET_PER_CLASS, "Black")
    final_d = safe_sample(pool_d, TARGET_PER_CLASS, "Draw")
    
    # D·ªçn d·∫πp pool g·ªëc ƒë·ªÉ nh·∫π RAM
    del pool_w, pool_l, pool_d
    gc.collect()

    # 3. SPLIT (CHIA T·∫¨P)
    def split_data(lst):
        n = len(lst)
        n1 = int(n * RATIOS[0])
        n2 = int(n * RATIOS[1])
        # ƒê·∫£m b·∫£o t·ªïng s·ªë l∆∞·ª£ng kh√¥ng v∆∞·ª£t qu√° n
        return lst[:n1], lst[n1:n1+n2], lst[n1+n2:n] 

    w_sets = split_data(final_w)
    l_sets = split_data(final_l)
    d_sets = split_data(final_d)

    # G·∫Øn th·∫ª ngu·ªìn g·ªëc: (offset, length, file_source)
    def tag(lst, src): 
        # G·∫Øn ƒë√∫ng ngu·ªìn file ƒë√£ truy·ªÅn v√†o (FILE_MAIN ho·∫∑c FILE_DRAW)
        # Tr√°nh heuristic theo t√™n file v√¨ d·ªÖ sai l·ªách
        return [(x[0], x[1], src) for x in lst]

    # Tagging c·∫ßn d√πng ƒë∆∞·ªùng d·∫´n ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a (FILE_MAIN/FILE_DRAW)
    train_items = tag(w_sets[0], FILE_MAIN) + tag(l_sets[0], FILE_MAIN) + tag(d_sets[0], FILE_DRAW)
    valid_items = tag(w_sets[1], FILE_MAIN) + tag(l_sets[1], FILE_MAIN) + tag(d_sets[1], FILE_DRAW)
    test_items = tag(w_sets[2], FILE_MAIN) + tag(l_sets[2], FILE_MAIN) + tag(d_sets[2], FILE_DRAW)

    # Shuffle l·∫ßn cu·ªëi
    random.shuffle(train_items)
    random.shuffle(valid_items)
    random.shuffle(test_items)
    
    # In ra s·ªë l∆∞·ª£ng cu·ªëi c√πng ƒë·ªÉ x√°c nh·∫≠n
    print(f"\n‚ú® T·ªîNG K·∫æT B·ªò D·ªÆ LI·ªÜU C√ÇN B·∫∞NG:")
    print(f" ¬† - Train: {len(train_items)} ({len(w_sets[0])} W / {len(l_sets[0])} B / {len(d_sets[0])} D)")
    print(f" ¬† - Valid: {len(valid_items)} ({len(w_sets[1])} W / {len(l_sets[1])} B / {len(d_sets[1])} D)")
    print(f" ¬† - Test: ¬†{len(test_items)} ({len(w_sets[2])} W / {len(l_sets[2])} B / {len(d_sets[2])} D)")

    del w_sets, l_sets, d_sets, final_w, final_l, final_d
    gc.collect()

    # 4. WRITING (GHI FILE T·ªêI ∆ØU BUFFER)
    print("\nüöÄ ƒêang ghi file...")
    
    # M·ªü file ngu·ªìn 1 l·∫ßn duy nh·∫•t
    f_main = open(FILE_MAIN, 'rb')
    f_draw = open(FILE_DRAW, 'rb')

    def write_dataset(filename, items):
        path = os.path.join(OUTPUT_DIR, filename)
        print(f"üíæ Ghi {filename} ({len(items)} v√°n)...")
        
        # Buffering = 1MB (T·ªëi ∆∞u cho t·ªëc ƒë·ªô ghi ƒëƒ©a)
        with open(path, 'wb', buffering=1024*1024) as f_out:
            for start, length, src_file in tqdm(items):
                # Ch·ªçn file handle ƒë√∫ng (s·ª≠ d·ª•ng so s√°nh ch√≠nh x√°c)
                handle = f_main if src_file == FILE_MAIN else f_draw
                
                # Vi·ªác seek v√† read n√†y l√† ƒëi·ªÉm m·∫•u ch·ªët c·ªßa t·ªëi ∆∞u t·ªëc ƒë·ªô ƒë·ªçc file ph√¢n t√°n
                handle.seek(start)
                data = handle.read(length)
                f_out.write(data)
                
                # ƒê·∫£m b·∫£o c√≥ hai d√≤ng tr·ªëng sau m·ªói v√°n c·ªù (chu·∫©n PGN)
                if not data.endswith(b"\n\n"):
                    f_out.write(b"\n\n")

    write_dataset('train.pgn', train_items)
    write_dataset('validation.pgn', valid_items)
    write_dataset('test.pgn', test_items)

    f_main.close()
    f_draw.close()
    print("\n‚úÖ HO√ÄN T·∫§T TUY·ªÜT ƒê·ªêI!")

if __name__ == "__main__":
    process_and_merge()